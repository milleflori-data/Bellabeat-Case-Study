{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7746251,"sourceType":"datasetVersion","datasetId":1041311},{"sourceId":8361160,"sourceType":"datasetVersion","datasetId":4969149},{"sourceId":8361351,"sourceType":"datasetVersion","datasetId":4969284}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"r","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Table of Contents:**\n\n* Ask\n* Process\n* Prepare\n* Analyze\n* Share","metadata":{}},{"cell_type":"markdown","source":"# Ask Phase \n## *What is the business-problem for my client Bellabeat; a smart device Health & Fitness tech company?*\n\nBellabeat wants to grow their company and reach more customers with their products that are geared toward\nwomen. The company has asked me, a (theoretical) Jr. Analyst to parse through a dataset that they have\nprovided and analyze the data in order to be able to give them a summary,recommendations,deliverables, and a presentation. The dataset is a small sample-size with no larger than 33 participants and was created in 2016 by Mobius via mTurk crowdsource surveys. The dataset was collected over a two-month time period with anonymous ID masking and variables such as: Date/Time,Total Steps, Calories Burned, Sedentary Time, Intensity, Sleep, Distance, Weight, BMI,and more. The variables are broken down into different files and tables; likely due to try to remain in good keeping with pop.sample size ratio of 10 observers per variable for Regression Analysis. Bellabeat would like the data input that was tracked using a FitBit smart device to be summarized. They have chosen this dataset because the product is similar to one of their products; a smart watch designed for women. ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Process The Data \n## Uploading, Importing, and Loading the Dataset. \n\nI upload, import, and load the dataset initially to Google Sheets from Kaggle. \nI used this dataset: ","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":7,"outputs":[{"ename":"ERROR","evalue":"Error in parse(text = x, srcfile = src): <text>:1:7: unexpected '/'\n1: https:/\n          ^\n","traceback":["Error in parse(text = x, srcfile = src): <text>:1:7: unexpected '/'\n1: https:/\n          ^\nTraceback:\n"],"output_type":"error"}]},{"cell_type":"markdown","source":"# Prepare The Data \n## Formating, Cleaning, Filtering, and Sorting The Files\n\nNext I work with all the file imports in a spreadsheet in Google Sheets so I can view, sort, clean, rename in a familiar format while I still learn R, SQL, and to use the various data hubs more fluently.\nIn Google Sheets, my versions log acts as a Changelog to track my amendments. Failing that, I've got jotted notes of each step spread on paper hardcopies. I make clean copies for me to manipulate in my spreadsheet. I rename the masked ID's to something visually cleaner and easier to view. Instead of the numerical strings I copy/paste each unique ID number and find/replace with a new generated ID using a User_One:User_Thirtythree format. I freeze the headers, pick a style format, and create colorblocks with \nthe new ID's. From there I observe the variables that the data was generated from and decide that it will\nbe advantageous to know what day of the week these activities happened on. I use the \"Activity Day\" Column to harvest the information from and this new data becomes \"Day of Week\" Column, which I have shared and made available on my profile in a cvs (see Dataset on profile, note: it is meant as a companion column to the dataset FitBit by Mobius). ","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-09T04:25:47.869272Z","iopub.execute_input":"2024-05-09T04:25:47.877691Z","iopub.status.idle":"2024-05-09T04:25:47.897019Z"},"trusted":true},"execution_count":6,"outputs":[{"ename":"ERROR","evalue":"Error in parse(text = x, srcfile = src): <text>:1:1: unexpected '/'\n1: /\n    ^\n","traceback":["Error in parse(text = x, srcfile = src): <text>:1:1: unexpected '/'\n1: /\n    ^\nTraceback:\n"],"output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-09T04:06:28.565178Z","iopub.execute_input":"2024-05-09T04:06:28.567069Z","iopub.status.idle":"2024-05-09T04:06:28.580389Z"},"trusted":true},"execution_count":5,"outputs":[{"ename":"ERROR","evalue":"Error in parse(text = x, srcfile = src): <text>:1:1: unexpected '/'\n1: /\n    ^\n","traceback":["Error in parse(text = x, srcfile = src): <text>:1:1: unexpected '/'\n1: /\n    ^\nTraceback:\n"],"output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}